// server.js
import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();
app.use(express.json());
app.use(cors());

// LM Studio ì„œë²„ ì£¼ì†Œ (ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ 1234 í¬íŠ¸)
const LMSTUDIO_API_URL = "http://localhost:1234/v1/chat/completions";

// âœ… /chat ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì´ìª½ìœ¼ë¡œ ìš”ì²­ì„ ë³´ëƒ„)
app.post("/chat", async (req, res) => {
  const { message } = req.body;

  try {
    // LM Studioë¡œ ìš”ì²­ ì „ë‹¬
    const response = await fetch(LMSTUDIO_API_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "meta-llama-3-8b-instruct", // LM Studioì—ì„œ ì„ íƒí•œ ëª¨ë¸ ì´ë¦„
        messages: [
          { role: "system", content: "You are a warm and empathetic psychological counselor." },
          { role: "user", content: message }
        ],
        temperature: 0.7,
        max_tokens: 512
      })
    });

    // JSON ë³€í™˜ ì‹œë„
    const data = await response.json();

    // LM Studio ì‘ë‹µ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
    console.log("ðŸ”¹ LM Studio ì‘ë‹µ:", data);

    // LM Studioê°€ ì •ìƒ ì‘ë‹µ ì‹œ
    if (data && data.choices && data.choices.length > 0) {
      res.json({ reply: data.choices[0].message.content });
    } else {
      res.json({ reply: "âš ï¸ LM Studioì—ì„œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." });
    }
  } catch (error) {
    console.error("âŒ LM Studio ì„œë²„ ì˜¤ë¥˜:", error);
    res.status(500).json({ error: "LM Studio ì—°ê²° ì‹¤íŒ¨" });
  }
});

// âœ… ì„œë²„ ì‹¤í–‰
const PORT = 3000;
app.listen(PORT, () => {
  console.log(`âœ… ì„œë²„ ì‹¤í–‰ ì¤‘: http://localhost:${PORT}`);
});
